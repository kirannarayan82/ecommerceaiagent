# -*- coding: utf-8 -*-
"""ecommercefraudagent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a9miC3mH08lnPAz2WKvlCi7i9NxGJEEO
"""

# prompt: generate a sample ecommerce transaction data in json format

import json
import random
from datetime import datetime, timedelta

def generate_transaction_data(num_transactions):
  """Generates sample e-commerce transaction data.

  Args:
    num_transactions: The number of transactions to generate.

  Returns:
    A list of dictionaries, where each dictionary represents a transaction.
  """
  transactions = []
  products = [
      {"product_id": "PROD001", "name": "Laptop", "price": 1200.00},
      {"product_id": "PROD002", "name": "Keyboard", "price": 75.00},
      {"product_id": "PROD003", "name": "Mouse", "price": 25.00},
      {"product_id": "PROD004", "name": "Monitor", "price": 300.00},
      {"product_id": "PROD005", "name": "Webcam", "price": 50.00},
      {"product_id": "PROD006", "name": "Headphones", "price": 100.00},
  ]
  customers = [
      {"customer_id": "CUST001", "name": "Alice"},
      {"customer_id": "CUST002", "name": "Bob"},
      {"customer_id": "CUST003", "name": "Charlie"},
      {"customer_id": "CUST004", "name": "David"},
      {"customer_id": "CUST005", "name": "Eve"},
  ]

  for i in range(num_transactions):
    transaction_id = f"TXN{i+1:05d}"
    customer = random.choice(customers)
    num_items = random.randint(1, 5)
    items = []
    total_amount = 0.0

    for _ in range(num_items):
      product = random.choice(products)
      quantity = random.randint(1, 3)
      item_total = round(product["price"] * quantity, 2)
      items.append({
          "product_id": product["product_id"],
          "name": product["name"],
          "price": product["price"],
          "quantity": quantity,
          "item_total": item_total
      })
      total_amount += item_total

    transaction_time = datetime.now() - timedelta(days=random.randint(0, 30), seconds=random.randint(0, 86400))

    transaction = {
        "transaction_id": transaction_id,
        "customer_id": customer["customer_id"],
        "customer_name": customer["name"],
        "transaction_time": transaction_time.isoformat(),
        "items": items,
        "total_amount": round(total_amount, 2)
    }
    transactions.append(transaction)

  return transactions

# Generate 10 sample transactions
sample_data = generate_transaction_data(10)

# Convert to JSON format
json_data = json.dumps(sample_data, indent=2)

json_data

# prompt: Use a bart model to convert any one transaction above to sentence

!pip install transformers torch

from transformers import BartForConditionalGeneration, BartTokenizer

# Load the BART model and tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Select one transaction from the generated sample data
# You can choose any index from 0 to 9 (since we generated 10 transactions)
transaction_to_convert = sample_data[0]

# Format the transaction data into a string that the BART model can process
# This is a simple string representation. More sophisticated formatting might yield better results.
transaction_string = f"Transaction ID: {transaction_to_convert['transaction_id']}, Customer: {transaction_to_convert['customer_name']} ({transaction_to_convert['customer_id']}), Time: {transaction_to_convert['transaction_time']}, Total Amount: ${transaction_to_convert['total_amount']}. Items: "
for item in transaction_to_convert['items']:
    transaction_string += f"{item['quantity']} x {item['name']} (${item['price']} each), "
# Remove the trailing comma and space
transaction_string = transaction_string.rstrip(', ')

# Encode the transaction string
input_ids = tokenizer.encode(transaction_string, return_tensors='pt', max_length=1024, truncation=True)

# Generate the sentence using the BART model
# You might need to experiment with different generation parameters for desired output.
output_ids = model.generate(input_ids, max_length=150, num_beams=4, early_stopping=True)

# Decode the generated output ids back into a sentence
generated_sentence = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print("Transaction Data (string):", transaction_string)
print("Generated Sentence:", generated_sentence)

# prompt: Take a  random fraud probabilty of ecommerce fraud of 0.6 for that transaction. and recommend a next best action to prevent fraud for the company. Use the best ecommerce  fraud prevention strategies, Use an approproate LLM

# Given fraud probability
fraud_probability = 0.6

# Determine the next best action based on the fraud probability
def recommend_next_best_action(probability):
    if probability >= 0.8:
        return "Immediately decline the transaction and flag the account for review. Consider contacting the customer directly through a verified channel."
    elif probability >= 0.5:
        return "Put the transaction on hold and request additional verification from the customer (e.g., two-factor authentication, micro-deposits). Alert fraud detection team for manual review."
    elif probability >= 0.2:
        return "Monitor the transaction and customer activity closely. Use step-up authentication for future transactions if suspicious patterns continue. Log the transaction for potential future analysis."
    else:
        return "Process the transaction as usual. Continue standard monitoring and fraud detection procedures."

recommended_action = recommend_next_best_action(fraud_probability)

# Integrate with the LLM to provide a more detailed explanation
def get_llm_recommendation(transaction_data_string, action, probability):
    prompt = f"Given the following transaction details: '{transaction_data_string}' and a fraud probability of {probability:.2f}, the recommended action is: '{action}'. Please provide a more detailed explanation of why this action is recommended and suggest potential additional steps the company can take to prevent similar fraud in the future, considering best e-commerce fraud prevention strategies like behavioral analytics, device fingerprinting, and machine learning models."

    # Encode the prompt
    input_ids = tokenizer.encode(prompt, return_tensors='pt', max_length=1024, truncation=True)

    # Generate the response using the BART model
    output_ids = model.generate(input_ids, max_length=300, num_beams=4, early_stopping=True) # Increased max_length for more detailed response

    # Decode the generated output
    llm_response = tokenizer.decode(output_ids[0], skip_special_tokens=True)

    return llm_response

# Assuming 'transaction_string' from the previous code block is available
llm_explanation = get_llm_recommendation(transaction_string, recommended_action, fraud_probability)

print("\nFraud Probability:", fraud_probability)
print("Recommended Next Best Action:", recommended_action)
print("\nLLM Explanation and Additional Recommendations:")
llm_explanation